{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Web Scraping con Selenium in Python\n",
    "Questo notebook mostra come utilizzare **Selenium**, una libreria Python per l'automazione del browser, per effettuare scraping di dati da siti web dinamici.\n",
    "\n",
    "## Obiettivi:\n",
    "- Installare e configurare Selenium\n",
    "- Eseguire il browser in modo automatico\n",
    "- Navigare su una pagina web\n",
    "- Estrarre informazioni da elementi HTML\n",
    "- Eseguire scraping da siti con contenuto dinamico (JavaScript)\n",
    "\n",
    "**Nota:** Usare Selenium con moderazione e nel rispetto dei termini di servizio dei siti web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()), options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Caricare una pagina web\n",
    "\n",
    "In questo esempio caricheremo la homepage di un sito di esempio per test di scraping: [https://quotes.toscrape.com](https://quotes.toscrape.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://quotes.toscrape.com\"\n",
    "driver.get(url)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Selezionare elementi HTML\n",
    "\n",
    "Useremo `driver.find_elements()` per selezionare tutte le citazioni presenti nella pagina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = driver.find_elements(By.CLASS_NAME, \"quote\")\n",
    "len(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Estrazione del contenuto\n",
    "\n",
    "Ogni elemento `quote` contiene una citazione, un autore e una lista di tag. Estrarremo queste informazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote in quotes:\n",
    "    text = quote.find_element(By.CLASS_NAME, \"text\").text\n",
    "    author = quote.find_element(By.CLASS_NAME, \"author\").text\n",
    "    tags = [tag.text for tag in quote.find_elements(By.CLASS_NAME, \"tag\")]\n",
    "    print(f\"Citazione: {text}\\nAutore: {author}\\nTag: {tags}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Navigare tra piÃ¹ pagine\n",
    "\n",
    "Molti siti hanno contenuti paginati. Mostriamo come fare scraping su piÃ¹ pagine cliccando su \"Next\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quotes = []\n",
    "\n",
    "while True:\n",
    "    quotes = driver.find_elements(By.CLASS_NAME, \"quote\")\n",
    "    for quote in quotes:\n",
    "        text = quote.find_element(By.CLASS_NAME, \"text\").text\n",
    "        author = quote.find_element(By.CLASS_NAME, \"author\").text\n",
    "        tags = [tag.text for tag in quote.find_elements(By.CLASS_NAME, \"tag\")]\n",
    "        all_quotes.append({\"text\": text, \"author\": author, \"tags\": tags})\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, \"next\")\n",
    "        next_button.find_element(By.TAG_NAME, \"a\").click()\n",
    "    except Exception:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Analisi dei dati\n",
    "\n",
    "Ora possiamo caricare le citazioni raccolte in un DataFrame per un'analisi o esportazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_quotes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Chiudere il browser\n",
    "\n",
    "Ãˆ buona norma chiudere il WebDriver al termine dello scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Conclusioni\n",
    "\n",
    "In questo notebook abbiamo imparato a:\n",
    "- Usare Selenium per aprire e controllare un browser\n",
    "- Navigare un sito e identificare elementi HTML\n",
    "- Estrarre contenuti e salvarli in un formato strutturato\n",
    "- Gestire piÃ¹ pagine dinamicamente\n",
    "\n",
    "ðŸš€ Estensioni possibili:\n",
    "- Gestione di CAPTCHA o login\n",
    "- Utilizzo di Selenium con altri strumenti (BeautifulSoup, pandas)\n",
    "- Screenshot e test automatici di UI\n",
    "\n",
    "ðŸ“Œ Ricorda: **scraping responsabile sempre.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
