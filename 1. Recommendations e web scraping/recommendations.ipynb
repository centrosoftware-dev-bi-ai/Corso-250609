{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Sistema di Raccomandazione basato su Similarità Semantica\n",
    "\n",
    "Questo notebook mostra un esempio pratico di recommendation system basato su embedding semantici.\n",
    "L'obiettivo è suggerire articoli alternativi o simili a partire dalla descrizione di un articolo dato.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Alternative tradizionali per la ricerca di articoli simili\n",
    "\n",
    "Prima dell’avvento degli embedding semantici, i sistemi di raccomandazione testuale spesso usavano metodi come:\n",
    "\n",
    "- **Keyword Matching**  \n",
    "  Ricerca basata sulla presenza di parole chiave identiche tra query e documenti.  \n",
    "  Svantaggi:  \n",
    "  - Sensibile a sinonimi e variazioni linguistiche  \n",
    "  - Non cattura il significato reale del testo  \n",
    "  - Risultati poco rilevanti se la formulazione cambia anche leggermente\n",
    "\n",
    "- **TF-IDF (Term Frequency - Inverse Document Frequency)**  \n",
    "  Pesa le parole in base alla loro frequenza nel documento e nella collezione, migliorando il keyword matching.  \n",
    "  Svantaggi:  \n",
    "  - Ancora basato su parole esatte, poco efficace con sinonimi o espressioni diverse  \n",
    "  - Non tiene conto del contesto o della semantica del testo  \n",
    "  - Funziona male con testi brevi o poco strutturati\n",
    "\n",
    "---\n",
    "\n",
    "### Vantaggi dell’approccio basato su embedding semantici\n",
    "\n",
    "- **Comprende il significato e il contesto** del testo, non solo la presenza di parole  \n",
    "- Gestisce sinonimi e variazioni linguistiche automaticamente  \n",
    "- Funziona bene anche con testi brevi o incompleti  \n",
    "- Permette di calcolare una **similarità continua** e più fine tra articoli, non solo match esatti  \n",
    "- Si presta facilmente a integrazioni con modelli di AI e sistemi scalabili\n",
    "\n",
    "---\n",
    "\n",
    "In sintesi, gli embedding semantici permettono un salto di qualità nel matching testuale, offrendo risultati più pertinenti e naturali rispetto ai metodi tradizionali basati su keyword o TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"codice\": \"A1001\",\n",
    "            \"descrizione\": \"Valvola in acciaio inox da 1 pollice\",\n",
    "            \"categoria\": \"valvole\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1002\",\n",
    "            \"descrizione\": \"Valvola in ottone da 1 pollice\",\n",
    "            \"categoria\": \"valvole\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1003\",\n",
    "            \"descrizione\": \"Rubinetto a sfera per impianti termici\",\n",
    "            \"categoria\": \"rubinetti\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1004\",\n",
    "            \"descrizione\": \"Valvola a farfalla con leva manuale\",\n",
    "            \"categoria\": \"valvole\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1005\",\n",
    "            \"descrizione\": \"Raccordo in PVC per tubi da 50mm\",\n",
    "            \"categoria\": \"raccordi\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1006\",\n",
    "            \"descrizione\": \"Valvola regolatrice in acciaio per alta pressione\",\n",
    "            \"categoria\": \"valvole\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1007\",\n",
    "            \"descrizione\": \"Rubinetto con attacco rapido\",\n",
    "            \"categoria\": \"rubinetti\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1008\",\n",
    "            \"descrizione\": \"Tubo in rame flessibile da 3 metri\",\n",
    "            \"categoria\": \"tubi\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1009\",\n",
    "            \"descrizione\": \"Raccordo in ottone per tubo flessibile\",\n",
    "            \"categoria\": \"raccordi\",\n",
    "        },\n",
    "        {\n",
    "            \"codice\": \"A1010\",\n",
    "            \"descrizione\": \"Valvola di ritegno per impianto idraulico\",\n",
    "            \"categoria\": \"valvole\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"descrizione\"])\n",
    "\n",
    "query_descrizione = df.loc[df[\"codice\"] == \"A1001\", \"descrizione\"].values[0]\n",
    "query_tfidf = vectorizer.transform([query_descrizione])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_tfidf = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "top_tfidf_idx = similarity_tfidf.argsort()[::-1][1:4]\n",
    "\n",
    "df[[\"codice\", \"descrizione\", \"categoria\"]].loc[top_tfidf_idx.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Cosa sono gli embedding?\n",
    "\n",
    "Un embedding è una rappresentazione numerica (vettore) di un oggetto, in questo caso la **descrizione di un articolo**.\n",
    "\n",
    "Gli embedding trasformano testo in punti in uno spazio multidimensionale. Articoli con descrizioni simili vengono mappati su **vettori vicini tra loro**.\n",
    "\n",
    "Nel nostro esempio, ogni descrizione diventa un vettore di centinaia di dimensioni (es. 1536 se si usa `text-embedding-ada-002`).\n",
    "\n",
    "Per visualizzarli useremo una **riduzione dimensionale** per proiettare i punti in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"database.index\")\n",
    "n = index.ntotal\n",
    "embeddings = np.vstack([index.reconstruct(i) for i in range(n)])\n",
    "df[\"embedding\"] = list(embeddings)\n",
    "embeddings_matrix = np.vstack(df[\"embedding\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"embedding\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "embedding_2d = pca.fit_transform(embeddings_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, row in df.iterrows():\n",
    "    x, y = embedding_2d[i]\n",
    "    plt.scatter(x, y, marker=\"o\", color=\"blue\")\n",
    "    plt.text(x + 0.01, y + 0.01, row[\"codice\"], fontsize=9)\n",
    "\n",
    "plt.title(\"Proiezione 2D degli articoli nello spazio degli embedding\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Similarità tra vettori\n",
    "\n",
    "Nel nostro modello, articoli simili hanno **vettori di embedding vicini** nello spazio.\n",
    "\n",
    "Per misurare la similarità usiamo la **cosine similarity** (o, nel caso di FAISS L2, la distanza euclidea):\n",
    "- Similarità alta = angolo piccolo → articoli semanticamente affini\n",
    "- Similarità bassa = angolo grande → articoli diversi\n",
    "\n",
    "Nell'immagine sopra, gli articoli vicini tra loro sono considerati alternative plausibili."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Cosine Similarity vs L2 Similarity (distanza euclidea)\n",
    "\n",
    "Quando confrontiamo vettori (come gli embedding), possiamo misurare quanto sono \"simili\" usando metriche diverse:\n",
    "\n",
    "- **Cosine Similarity**: misura l'angolo tra due vettori. Indica quanto sono orientati nella stessa direzione, indipendentemente dalla loro lunghezza.\n",
    "  - Valori tra -1 e 1.\n",
    "  - 1 = vettori perfettamente allineati (massima similarità).\n",
    "  - 0 = vettori ortogonali (nessuna similarità).\n",
    "  - -1 = vettori opposti.\n",
    "\n",
    "- **L2 Similarity** (o distanza euclidea): misura la distanza \"lineare\" tra due punti nello spazio.\n",
    "  - Più la distanza è piccola, più i vettori sono vicini.\n",
    "  - La distanza è sempre ≥ 0.\n",
    "\n",
    "In generale:\n",
    "\n",
    "- La cosine similarity si concentra sull'**orientamento** del vettore.\n",
    "- La L2 similarity si concentra sulla **distanza spaziale**.\n",
    "\n",
    "---\n",
    "\n",
    "Nei motori di ricerca vettoriali come FAISS, a seconda del tipo di indice, si usa una o l'altra: \n",
    "- Indici basati su distanza L2 cercano i vettori più **vicini** spazialmente.\n",
    "- Indici basati su cosine similarity cercano i vettori con angoli più **piccoli**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def l2_distance(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "\n",
    "# Vettori di esempio (2D per visualizzazione)\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([0.5, 0.5])\n",
    "v3 = np.array([-1, 0])\n",
    "\n",
    "print(\"Cosine similarity v1-v2:\", cosine_similarity(v1, v2))\n",
    "print(\"L2 distance v1-v2:\", l2_distance(v1, v2))\n",
    "print(\"Cosine similarity v1-v3:\", cosine_similarity(v1, v3))\n",
    "print(\"L2 distance v1-v3:\", l2_distance(v1, v3))\n",
    "\n",
    "# Visualizzazione\n",
    "origin = np.array([0, 0])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.quiver(*origin, *v1, color=\"r\", scale=3, label=\"v1\")\n",
    "plt.quiver(*origin, *v2, color=\"g\", scale=3, label=\"v2\")\n",
    "plt.quiver(*origin, *v3, color=\"b\", scale=3, label=\"v3\")\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title(\"Visualizzazione vettori e loro angoli\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raccomanda_simili(codice_articolo: str, top_n: int = 5):\n",
    "    articolo = df[df[\"codice\"] == codice_articolo]\n",
    "    if articolo.empty:\n",
    "        raise ValueError(\"Codice articolo non trovato\")\n",
    "\n",
    "    query_embedding = np.array(articolo[\"embedding\"].iloc[0]).reshape(1, -1)\n",
    "    distanze, indici = index.search(query_embedding, top_n + 1)\n",
    "\n",
    "    risultati = df.iloc[indici[0]]\n",
    "    risultati[\"similarità\"] = np.exp(-distanze[0])\n",
    "    risultati = risultati[risultati[\"codice\"] != codice_articolo]\n",
    "    return risultati[[\"codice\", \"descrizione\", \"categoria\", \"similarità\"]].sort_values(\n",
    "        by=\"similarità\", ascending=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "raccomanda_simili(\"A1001\", top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostra_simili_2d(codice_articolo: str, top_n: int = 5):\n",
    "    articolo_idx = df.index[df[\"codice\"] == codice_articolo].item()\n",
    "    query_emb = embeddings_matrix[articolo_idx].reshape(1, -1)\n",
    "    _, indici = index.search(query_emb, top_n + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(len(df)):\n",
    "        x, y = embedding_2d[i]\n",
    "        if i == articolo_idx:\n",
    "            plt.scatter(\n",
    "                x, y, marker=\"x\", color=\"red\", s=100, label=\"Articolo richiesto\"\n",
    "            )\n",
    "        elif i in indici and i != articolo_idx:\n",
    "            plt.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                marker=\"o\",\n",
    "                color=\"green\",\n",
    "                s=80,\n",
    "                label=\"Simile\"\n",
    "                if \"Simile\" not in plt.gca().get_legend_handles_labels()[1]\n",
    "                else \"\",\n",
    "            )\n",
    "        else:\n",
    "            plt.scatter(x, y, marker=\"o\", color=\"lightgray\")\n",
    "\n",
    "        plt.text(x + 0.01, y + 0.01, df.iloc[i][\"codice\"], fontsize=8)\n",
    "\n",
    "    plt.title(f\"Articolo '{codice_articolo}' e simili nello spazio 2D\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostra_simili_2d(\"A1001\", top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Conclusioni\n",
    "\n",
    "Abbiamo costruito un sistema di recommendation che:\n",
    "\n",
    "1. Usa **embedding semantici** di Azure OpenAI per rappresentare articoli come vettori numerici.\n",
    "2. Indica articoli simili cercandoli in uno spazio vettoriale con **FAISS**.\n",
    "3. Mostra un'alternativa moderna a TF-IDF e keyword matching, capace di cogliere la **semantica**.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
