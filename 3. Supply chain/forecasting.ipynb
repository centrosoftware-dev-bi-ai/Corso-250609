{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Forecast delle vendite con variabili esogene\n",
    "Questo notebook mostra un esempio didattico di previsione delle vendite utilizzando modelli di machine learning. Include variabili esogene come promozioni, prezzo e temperatura, e confronta modelli diversi (Ridge e XGBoost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Simulazione dei dati\n",
    "Simuliamo dati giornalieri per 3 anni, con vendite influenzate da fattori esogeni come promozioni, prezzo e temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start=\"2020-01-01\", end=\"2022-12-31\", freq=\"D\")\n",
    "n = len(date_range)\n",
    "\n",
    "base_sales = 200 + 10 * np.sin(2 * np.pi * date_range.dayofyear / 365)\n",
    "promo = np.random.binomial(1, 0.1, size=n)\n",
    "price = 10 + np.random.normal(0, 0.5, size=n)\n",
    "temperature = (\n",
    "    15\n",
    "    + 10 * np.sin(2 * np.pi * (date_range.dayofyear + 50) / 365)\n",
    "    + np.random.normal(0, 2, size=n)\n",
    ")\n",
    "\n",
    "sales = (\n",
    "    base_sales\n",
    "    + promo * 40\n",
    "    - price * 5\n",
    "    + temperature * 1.5\n",
    "    + np.random.normal(0, 10, size=n)\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": date_range,\n",
    "        \"sales\": sales,\n",
    "        \"promo\": promo,\n",
    "        \"price\": price,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    ")\n",
    "df.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "df[\"sales\"].plot()\n",
    "plt.title(\"Vendite giornaliere (originali)\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Vendite\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "Creiamo nuove variabili da usare come input: informazioni temporali, valori lag e medie mobili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dayofweek\"] = df.index.dayofweek\n",
    "df[\"month\"] = df.index.month\n",
    "df[\"lag_1\"] = df[\"sales\"].shift(1)\n",
    "df[\"rolling_mean_7\"] = df[\"sales\"].rolling(window=7).mean()\n",
    "df[\"rolling_std_7\"] = df[\"sales\"].rolling(window=7).std()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "df[[\"sales\", \"lag_1\", \"rolling_mean_7\"]].iloc[-100:].plot()\n",
    "plt.title(\"Ultimi 100 giorni: vendite e variabili derivate (lag, rolling)\")\n",
    "plt.ylabel(\"Valore\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "Suddividiamo il dataset in un set di addestramento e uno di test basandoci sull'ordine temporale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "features = [\n",
    "    \"promo\",\n",
    "    \"price\",\n",
    "    \"temperature\",\n",
    "    \"dayofweek\",\n",
    "    \"month\",\n",
    "    \"lag_1\",\n",
    "    \"rolling_mean_7\",\n",
    "    \"rolling_std_7\",\n",
    "]\n",
    "X_train = train[features]\n",
    "y_train = train[\"sales\"]\n",
    "X_test = test[features]\n",
    "y_test = test[\"sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 4. Standardizzazione delle feature\n",
    "Applichiamo lo scaling alle feature per modelli sensibili alla scala, come Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 5. Regressione Ridge\n",
    "Utilizziamo una regressione lineare con regolarizzazione L2 (Ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test_scaled)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "print(f\"MAE Ridge: {mae_ridge:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 6. XGBoost Regressor\n",
    "Modello di boosting gradientale, efficace con dati tabellari e non lineari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"MAE XGBoost: {mae_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 7. Visualizzazione dei risultati\n",
    "Confrontiamo graficamente le previsioni di entrambi i modelli con le vendite reali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test.index, y_test, label=\"Osservato\")\n",
    "plt.plot(y_test.index, y_pred_ridge, label=\"Ridge\", alpha=0.7)\n",
    "plt.plot(y_test.index, y_pred_xgb, label=\"XGBoost\", alpha=0.7)\n",
    "plt.title(\"Confronto previsioni vendite\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(\n",
    "    y_test.index, 100 * np.abs(y_test - y_pred_ridge) / y_test, label=\"Errore Ridge\"\n",
    ")\n",
    "plt.plot(\n",
    "    y_test.index, 100 * np.abs(y_test - y_pred_xgb) / y_test, label=\"Errore XGBoost\"\n",
    ")\n",
    "plt.title(\"Errore percentuale giornaliero\")\n",
    "plt.ylabel(\"Errore (%)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 8. Reti neurali semplici (Deep Learning)\n",
    "Ora applichiamo una rete neurale feedforward semplice con Keras per confrontare le performance con i modelli precedenti. Questo approccio è utile per catturare non linearità complesse nelle relazioni tra feature e target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dl = model.predict(X_test_scaled).flatten()\n",
    "mae_dl = mean_absolute_error(y_test, y_pred_dl)\n",
    "print(f\"MAE Rete Neurale: {mae_dl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test.index, y_test, label=\"Osservato\", linewidth=2)\n",
    "plt.plot(y_test.index, y_pred_dl, label=\"Rete Neurale\", alpha=0.6)\n",
    "plt.title(\"Previsioni rete neurale\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(y_test.index, 100 * np.abs(y_test - y_pred_dl) / y_test, label=\"Errore MLP\")\n",
    "plt.title(\"Errore percentuale giornaliero\")\n",
    "plt.ylabel(\"Errore (%)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
